{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Matrix Factorization - Alternating Least Squares in Python</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS is Matrix Factorization Algorithm. Matrix Factorization decomposes a large matrix into products of matrices.<br>\n",
    "<br>\n",
    "R = U * V<br>\n",
    "<br>\n",
    "For example in recommendation systems, let us consider R as a matrix of User (Rows) and Ratings (Columns). Matrix factorization will allow us to discover the latent features that define the interactions between User and Ratings. In other words, ALS uncovers the latent features.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Data-Exploration\" data-toc-modified-id=\"Data-Exploration-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Exploration</a></span></li><li><span><a href=\"#Alternating-Least-Squares\" data-toc-modified-id=\"Alternating-Least-Squares-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Alternating Least Squares</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Results</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "FILE_PATH = \"./data/Movielens/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "The original dataset has been proprocessed to filter out and keep only the top users and items.<br>\n",
    "Please refer to the preprocessing notebook in the repo for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## user_to_item_map={}  ## Key:= User_id, Value:= [list of items] \n",
    "## item_to_user_map={}  ## Key:= item_id, Value:=[list of users] \n",
    "## train_ratings={}      ## Key:= (User_id, item_id) Value:=Rating \n",
    "## test_ratings={}       ## Key:= (User_id, item_id) Value:=Rating \n",
    "\n",
    "with open(FILE_PATH+'user_to_item_map.pkl', 'rb') as fp:\n",
    "    user_to_item_map=pickle.load(fp)\n",
    "\n",
    "with open(FILE_PATH+'item_to_user_map.pkl', 'rb') as fp:\n",
    "    item_to_user_map=pickle.load(fp)\n",
    "\n",
    "with open(FILE_PATH+'train_ratings.pkl', 'rb') as fp:\n",
    "    train_ratings=pickle.load(fp)\n",
    "\n",
    "with open(FILE_PATH+'test_ratings.pkl', 'rb') as fp:\n",
    "    test_ratings=pickle.load(fp)\n",
    "\n",
    "with open(FILE_PATH+'user_statistics.pkl', 'rb') as fp:\n",
    "    user_statistics=pickle.load(fp)\n",
    "    \n",
    "with open(FILE_PATH+'item_statistics.pkl', 'rb') as fp:\n",
    "    item_statistics=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 200\n",
      "Number of unique items: 600\n",
      "Total ratings in the dataset: 95871\n",
      "User-Item matrix size: 120000\n",
      "User-Item matrix empty percentage: 20.1075\n"
     ]
    }
   ],
   "source": [
    "n_users=len(user_to_item_map)\n",
    "n_items=len(item_to_user_map)\n",
    "user_ids=range(n_users)\n",
    "item_ids=range(n_items)\n",
    "matrix_size=n_users*n_items\n",
    "n_ratings=len(train_ratings)+len(test_ratings)\n",
    "\n",
    "print(\"Number of unique users:\",n_users)\n",
    "print(\"Number of unique items:\",n_items)\n",
    "print(\"Total ratings in the dataset:\",n_ratings)\n",
    "\n",
    "print(\"User-Item matrix size:\",matrix_size)\n",
    "print(\"User-Item matrix empty percentage:\",(matrix_size-n_ratings)*100/(matrix_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(latent_factors):\n",
    "    user_weights={}\n",
    "    item_weights={}\n",
    "    user_bias=defaultdict(int)\n",
    "    item_bias=defaultdict(int)\n",
    "    \n",
    "    for user in user_ids:\n",
    "        user_weights[user]=np.random.rand(latent_factors)\n",
    "\n",
    "    for item in item_ids:\n",
    "        item_weights[item]=np.random.rand(latent_factors)\n",
    "\n",
    "    mean=np.mean(list(train_ratings.values()))\n",
    "    \n",
    "    return user_weights,item_weights,user_bias,item_bias,mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS(user_weights,item_weights,user_bias,item_bias,mean,iterations,reg,latent_factors):\n",
    "    n=latent_factors\n",
    "    for i in range(iterations):\n",
    "        print(\"Iteration: {} .........\".format(i))\n",
    "        for user in user_ids:\n",
    "            A=np.zeros([n,n])\n",
    "            b=np.zeros([1,n])\n",
    "            #if user not in user_to_item_map: continue\n",
    "            for item in user_to_item_map[user]:\n",
    "                A+=np.outer(item_weights[item],item_weights[item].T)+reg*(np.eye(n))\n",
    "                b+=(train_ratings[(user,item)]-item_bias[item]-user_bias[user]-mean)*item_weights[item]\n",
    "\n",
    "            user_weights[user]=np.linalg.solve(A,b.T).T\n",
    "\n",
    "        for item in item_ids:\n",
    "            A=np.zeros([n,n])\n",
    "            b=np.zeros([1,n])\n",
    "            #if item not in item_to_user_map: continue\n",
    "            for user in item_to_user_map[item]:\n",
    "                A+=np.outer(user_weights[user],user_weights[user].T)+reg*(np.eye(n))\n",
    "                b+=(train_ratings[(user,item)]-item_bias[item]-user_bias[user]-mean)*user_weights[user]\n",
    "            item_weights[item]=np.linalg.solve(A,b.T).T\n",
    "\n",
    "        for user in user_ids:\n",
    "            mlen=len(user_to_item_map[user])\n",
    "            item_bias[item]=0\n",
    "            for item in user_to_item_map[user]:\n",
    "                item_bias[item]=(1.0/(mlen+reg))*(train_ratings[(user,item)]-np.dot(user_weights[user],item_weights[item].T)-user_bias[user]-mean)[0]\n",
    "\n",
    "        for item in item_ids:\n",
    "            ulen=len(item_to_user_map[item])\n",
    "            user_bias[user]=0\n",
    "            for user in item_to_user_map[item]:\n",
    "                user_bias[user]=(1.0/(ulen+reg))*(train_ratings[(user,item)]-np.dot(user_weights[user],item_weights[item].T)-item_bias[item]-mean)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_MSE(dataset,user_weights,item_weights,user_bias,item_bias,mean):\n",
    "    errors=[]\n",
    "    for (user,item),rating in dataset.items():\n",
    "        #if user in user_weights and item in item_weights:\n",
    "        pred=np.dot(user_weights[user],item_weights[item].T)[0][0]+item_bias[item]+user_bias[user]+mean\n",
    "        errors.append((pred-rating)**2)\n",
    "\n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 .........\n",
      "Iteration: 1 .........\n",
      "Iteration: 2 .........\n",
      "Iteration: 3 .........\n",
      "Iteration: 4 .........\n",
      "Length of user and item weight vectors:  10\n",
      "Mean rating of the train data:  3.495066111495438\n"
     ]
    }
   ],
   "source": [
    "latent_factors=10  ## No. of latent factors\n",
    "reg=0.01\n",
    "iterations=5\n",
    "user_weights,item_weights,user_bias,item_bias,mean = initialize(latent_factors)\n",
    "ALS(user_weights,item_weights,user_bias,item_bias,mean,iterations,reg,latent_factors)\n",
    "\n",
    "print(\"Length of user and item weight vectors: \",latent_factors)\n",
    "print(\"Mean rating of the train data: \",mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error:  0.44707146525930824\n",
      "Test error:  0.5955405833436895\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error: \",calculate_MSE(train_ratings,user_weights,item_weights,user_bias,item_bias,mean))\n",
    "print(\"Test error: \",calculate_MSE(test_ratings,user_weights,item_weights,user_bias,item_bias,mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://en.wikipedia.org/wiki/Recommender_system <br>\n",
    "2. https://www.udemy.com/recommender-systems/ <br>\n",
    "3. https://www.quora.com/What-is-the-Alternating-Least-Squares-method-in-recommendation-systems-And-why-does-this-algorithm-work-intuition-behind-this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
